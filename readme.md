
"# Situating and Comparing Artificial Neural Networks in a Unified Brain-like Space\n",
"\n",
"## Overview\n",
"This repository provides code for computing graph metrics from spatial attention patterns across different models and brain functional networks.\n",
"\n",
"## Repository Structure\n",
"\n",
"### 1. Model Processing (`model-process/`)\n",
"Contains code for computing graph metrics from spatial attention patterns of various model families.\n",
"\n",
"#### Key Files:\n",
"### Vision Transformers (ViT, ViT-Variants)\n",
"  - `vit-process.py`\n",
"  - `dinov3-process.py`\n",
"\n",
"### Large Language Models (LLMs)\n",
"  - `gpt2-process.py`\n",
"  - `bert-process.py`\n",
"\n",
"### Large Multimodal Models (LMMs)\n",
"  - `clip-language.py`, `clip-vision.py`\n",
"  - `blip-language.py`, `blip-vision.py`\n",
"\n",
"### RoPE-based Models （LLM-RoPEs、LMM-RoPEs）\n",
"- **LLMs with Rotary Position Embeddings**\n",
"  - `qwen-process.py`\n",
"- **LMMs with Rotary Position Embeddings**\n",
"  - `qwen-language-process.py`, `qwen-vision-process.py`\n",
"  - `deepseek-language-process.py`\n",
"\n",
"#### Usage Requirements:\n",
"Before running any model processing scripts, modify these key parameters:\n",
"1. **Model List**: Specify target list of model names in `models`\n",
"2. **Cache Directory**: Set `your_cache_dir` for model downloads\n",
"3. **Output Directory**: Set `your_base_dir` for results storage\n",
"4. **Access Tokens**: For gated models, add your HuggingFace access token in the download section (request from official model pages)\n",
"\n",
"#### Extension Notes:\n",
"For other and new RoPE-based LLM/LMM models, adapt existing examples by:\n",
"- Modifying the model loader\n",
"- Adjusting configuration extraction based on model architecture\n",
"- Updating Q/K weight extraction methods according to model nesting structure\n",
"\n",
"### 2. Brain Network Processing (`brain-process.ipynb`)\n",
"Computes graph metrics for brain functional networks.\n",
"\n",
"#### Prerequisites:\n",
"- Prepare multiple pre-extracted brain network connectivity matrices (`.mat` files)\n",
"- Ensure main diagonal elements are set to zero in all matrices\n",
"\n",
"### 3. Pre-computed Results\n",
"- `model-result/`: Graph metrics for 151 models used in the paper\n",
"- `brainnetwork-result.json`: Graph metrics for 7 group-level brain functional networks\n",
"\n",
"### 4. Brain-Like Space Analysis (`brain-like_space.ipynb`)\n",
"Constructs the brain-like space and computes brain-like scores.\n",
"\n",
"#### Quick Start:\n",
"Use the provided `model-result/` and `brainnetwork-result.json` directories to:\n",
"- Visualize the brain-like space\n",
"- Generate brain-like score result files\n",
"\n",
"## Requirements\n",
"\n",
"### Core Dependencies\n",
"- torch==2.8.0\n",
"- transformers==4.56.1\n",
"- accelerate==1.10.1\n",
"- safetensors==0.6.2\n",
"- timm==1.0.14\n",
"- networkx==3.4.2\n",
"- python-louvain==0.16\n",
"- numpy==2.2.6\n",
"- scipy==1.15.3\n",
"\n",
"**Note:** `transformers` and `accelerate` versions may need adjustment for specific models. Some models require different versions for compatibility.\n",
"\n",
"## Citation\n",
"If you use this code in your research, please cite our accompanying paper：Situating and Comparing Artificial Neural Networks in a Unified Brain-like Space"
   
 
