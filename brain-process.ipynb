{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4904d3bb",
   "metadata": {},
   "source": [
    "### Preprocessing of Functional Brain Network Connectivity Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550db777",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import glob\n",
    "import scipy.io\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def safe_minmax_scale(matrix, epsilon=1e-5, delta=1e-5):\n",
    "    \"\"\"\n",
    "    Perform min-max scaling on non-zero elements of the matrix with safety bounds\n",
    "    \n",
    "    Args:\n",
    "        matrix: Input connectivity matrix\n",
    "        epsilon: Small value to prevent values from reaching exactly 1\n",
    "        delta: Small value to prevent values from reaching exactly 0\n",
    "    \n",
    "    Returns:\n",
    "        Scaled matrix where non-zero elements are normalized to [delta, 1-epsilon]\n",
    "    \"\"\"\n",
    "    # Create mask to identify non-zero elements\n",
    "    mask = matrix != 0\n",
    "    values = matrix[mask]\n",
    "    \n",
    "    # Handle case where all non-zero values are the same\n",
    "    if len(values) == 0:\n",
    "        return matrix.copy()\n",
    "        \n",
    "    min_val = np.min(values)\n",
    "    max_val = np.max(values)\n",
    "    \n",
    "    if max_val == min_val:\n",
    "        return matrix.copy()\n",
    "    \n",
    "    # Apply min-max scaling only to non-zero elements\n",
    "    scaled = matrix.copy()\n",
    "    scaled[mask] = delta + ((matrix[mask] - min_val) / (max_val - min_val)) * (1 - epsilon - delta)\n",
    "    return scaled\n",
    "\n",
    "def masked_softmax(matrix):\n",
    "    \"\"\"\n",
    "    Apply row-wise softmax only to non-zero elements with numerical stability\n",
    "    \n",
    "    Args:\n",
    "        matrix: Input connectivity matrix\n",
    "        \n",
    "    Returns:\n",
    "        Matrix with softmax applied row-wise to non-zero elements\n",
    "    \"\"\"\n",
    "    rowwise_result = np.zeros_like(matrix)\n",
    "    \n",
    "    # Process each row individually\n",
    "    for i in range(matrix.shape[0]):\n",
    "        row = matrix[i]\n",
    "        mask = row != 0\n",
    "        values = row[mask]\n",
    "        \n",
    "        # Skip rows with no non-zero elements\n",
    "        if len(values) == 0:\n",
    "            continue\n",
    "            \n",
    "        # Numerical stability: subtract max value to prevent overflow\n",
    "        shifted = values - np.max(values)\n",
    "        exps = np.exp(shifted)\n",
    "        softmaxed = exps / np.sum(exps)\n",
    "        \n",
    "        # Apply softmax only to non-zero positions\n",
    "        rowwise_result[i, mask] = softmaxed\n",
    "        \n",
    "    return rowwise_result\n",
    "\n",
    "def process_mat_files(\n",
    "    folder_path,\n",
    "    output_file,\n",
    "    save_to_file=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Process all functional brain network connectivity matrices in a folder\n",
    "    \n",
    "    Args:\n",
    "        folder_path: Path to folder containing multiple .mat files with connectivity matrices\n",
    "        output_file: Path for output JSON file\n",
    "        save_to_file: Whether to save results to file\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing processed adjacency matrices\n",
    "    \"\"\"\n",
    "    # Find all .mat files in the folder\n",
    "    mat_files = glob.glob(os.path.join(folder_path, '*.mat'))\n",
    "    \n",
    "    # Extract matrix names from filenames\n",
    "    matrix_names = [os.path.splitext(os.path.basename(file))[0].split('_')[0] for file in mat_files]\n",
    "    adjacency_matrices = {}\n",
    "\n",
    "    # Process each .mat file\n",
    "    for file_path, matrix_name in zip(mat_files, matrix_names):\n",
    "        # Load .mat file data\n",
    "        data = scipy.io.loadmat(file_path)\n",
    "        \n",
    "        # Check if the expected matrix name exists in the .mat file\n",
    "        if matrix_name not in data:\n",
    "            print(f\"Warning: Key '{matrix_name}' not found in {file_path}, skipping this file.\")\n",
    "            continue\n",
    "\n",
    "        # Extract and convert matrix to float\n",
    "        matrix = data[matrix_name].astype(float)\n",
    "        # Keep only positive connections (set negative values to zero)\n",
    "        matrix[matrix < 0] = 0\n",
    "        # Apply row-wise softmax to non-zero elements\n",
    "        matrix = masked_softmax(matrix) \n",
    "        # Apply min-max scaling to non-zero elements\n",
    "        matrix = safe_minmax_scale(matrix)\n",
    "\n",
    "        # Store processed matrix in dictionary\n",
    "        adjacency_matrices[matrix_name] = matrix.tolist()\n",
    "\n",
    "    # Save results to JSON file if requested\n",
    "    if save_to_file:\n",
    "        with open(output_file, 'w') as json_file:\n",
    "            json.dump(adjacency_matrices, json_file, indent=4)\n",
    "        print(f\"Results saved to {output_file}\")\n",
    "\n",
    "    return adjacency_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb759c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "folder_path = 'your_folder_path'\n",
    "output_file = 'your_output_file_path.json'\n",
    "process_mat_files(\n",
    "    folder_path,\n",
    "    output_file,\n",
    "    save_to_file=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197ad103",
   "metadata": {},
   "source": [
    "### Computation of Graph Metrics for Functional Brain Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8797a871",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import community  \n",
    "import random\n",
    "\n",
    "def compute_graph_metrics(brain_graph_results_path, file_path, save_to_file=False):\n",
    "    \"\"\"\n",
    "    Compute graph metrics (divided into connection strength graph and path length graph categories):\n",
    "    - Weighted global clustering coefficient (Barrat formula)\n",
    "    - Weighted modularity (Louvain algorithm)\n",
    "    - Weighted average shortest path\n",
    "    - Global efficiency\n",
    "    - Degree distribution statistics\n",
    "\n",
    "    Parameters:\n",
    "      brain_graph_results_path: Path to JSON file containing aggregated matrices\n",
    "      file_path: Path to save graph metrics results\n",
    "      save_to_file: Whether to save results to file\n",
    "    Returns:\n",
    "      graph_metric: Dictionary of graph metrics for each model (including both connection strength and path length graph metrics)\n",
    "    \"\"\"\n",
    "    # 1. Read JSON file\n",
    "    with open(brain_graph_results_path, 'r') as f:\n",
    "        aggregation_results = json.load(f)\n",
    "    \n",
    "    graph_metric = {}  # Store graph metrics for each model\n",
    "\n",
    "    # 2. Iterate through each model\n",
    "    for model_name, matrix in aggregation_results.items():\n",
    "        # Convert list to NumPy array\n",
    "        matrix = np.array(matrix)\n",
    "        n = matrix.shape[0]\n",
    "        \n",
    "        # ðŸ”¹ Connection Strength Graph\n",
    "        conn_matrix = (matrix + matrix.T) / 2  # Symmetrize\n",
    "        G_conn = nx.from_numpy_array(conn_matrix)\n",
    "\n",
    "        # ðŸ”¹ Path Length Graph\n",
    "        distance_matrix = np.where(matrix != 0, 1 - np.abs(matrix), np.inf)\n",
    "        distance_matrix = (distance_matrix + distance_matrix.T) / 2  # Symmetrize\n",
    "        G_dist = nx.from_numpy_array(distance_matrix)\n",
    "\n",
    "        # 3. Calculate graph metrics\n",
    "        metrics = {}\n",
    "\n",
    "        # Structural metrics (based on connection strength graph G_conn)\n",
    "        try:\n",
    "            metrics['clustering'] = nx.average_clustering(G_conn, weight='weight')\n",
    "        except Exception:\n",
    "            metrics['clustering'] = None\n",
    "\n",
    "        try:\n",
    "            partition = community.best_partition(G_conn, weight='weight', random_state=0)\n",
    "            metrics['modularity'] = community.modularity(partition, G_conn, weight='weight')\n",
    "        except Exception:\n",
    "            metrics['modularity'] = None\n",
    "\n",
    "        try:\n",
    "            degrees = [deg for _, deg in G_conn.degree(weight='weight')]\n",
    "            metrics['average_degree'] = np.mean(degrees)\n",
    "            metrics['degree_std'] = np.std(degrees)\n",
    "        except Exception:\n",
    "            metrics['average_degree'] = None\n",
    "            metrics['degree_std'] = None\n",
    "\n",
    "        # Path-based metrics (based on path length graph G_dist)\n",
    "        try:\n",
    "            if nx.is_connected(G_dist):\n",
    "                metrics['average_shortest_path'] = nx.average_shortest_path_length(G_dist, weight='weight')\n",
    "            else:\n",
    "                metrics['average_shortest_path'] = float('inf')\n",
    "        except Exception:\n",
    "            metrics['average_shortest_path'] = None\n",
    "\n",
    "        try:\n",
    "            length = dict(nx.all_pairs_dijkstra_path_length(G_dist, weight='weight'))\n",
    "            total_eff = sum(1 / d for src in length for tgt, d in length[src].items() if src != tgt)\n",
    "            metrics['global_efficiency'] = total_eff / (n * (n - 1))\n",
    "        except Exception:\n",
    "            metrics['global_efficiency'] = None\n",
    "\n",
    "        \n",
    "        # 4. Store results for this model\n",
    "        graph_metric[model_name] = metrics\n",
    "\n",
    "    # 5. Save results to JSON file (optional)\n",
    "    if save_to_file:\n",
    "        with open(file_path, 'w') as f:\n",
    "            json.dump(graph_metric, f, indent=4)\n",
    "        print(f\"Graph metrics saved to {file_path}\")\n",
    "    \n",
    "    return graph_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6225b95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "graph_measure = compute_graph_metrics('your_brain_graph_results_path.json', 'your_output_file_path.json', save_to_file=True)\n",
    "##'your_brain_graph_results_path.json' should be the 'your_output_file_path.json' from the previous section"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
